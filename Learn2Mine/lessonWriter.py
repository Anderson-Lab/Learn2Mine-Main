# coding: utf-8
def createTutorialProbs(hint,code,id=0):
	hintHTML = '<div id="hint'+str(id)+'" style="display:none;"><b>Hint:</b> '+hint+'</div><a id="hint'+str(id)+'link" href="javascript:;" onClick="document.getElementById(\'hint'+str(id)+'\').style.display=\'inline\'; document.getElementById(\'hint'+str(id)+'link\').style.display=\'none\';">Hint</a>'
	showlineHTML = ''
	codelist = code.split('<br>')
	for i in range(len(codelist)): # Creates the show line divs
		showlineHTML += '<div class="linecode'+str(id)+'" id="showline'+str(i)+str(id)+'" style="display:none;">'+codelist[i]+'</div>'
	for i in range(len(codelist)):
		if(i == 0):
			showlineHTML += '<a class="linelink'+str(id)+'" id="showline'+str(id)+'link" href="javascript:;" onClick="$(\'#showline'+str(i)+str(id)+'\').css(\'display\',\'block\'); $(\'#showline'+str(id)+'link\').css(\'display\',\'none\'); $(\'#showline'+str(id)+'link'+str(i+1)+'\').css(\'display\',\'block\');">Show Line of Code</a>'
		elif(i == len(codelist) - 1):
			showlineHTML += '<a class="linelink'+str(id)+'" style="display:none;" id="showline'+str(id)+'link'+str(i)+'" href="javascript:;" onClick="$(\'#showline'+str(i)+str(id)+'\').css(\'display\',\'block\'); $(\'#showline'+str(id)+'link'+str(i)+'\').css(\'display\',\'none\');">Show Last Line of Code</a>'
		else:
			showlineHTML += '<a class="linelink'+str(id)+'" style="display:none;" id="showline'+str(id)+'link'+str(i)+'" href="javascript:;" onClick="$(\'#showline'+str(i)+str(id)+'\').css(\'display\',\'block\');$(\'#showline'+str(id)+'link'+str(i)+'\').css(\'display\',\'none\'); $(\'#showline'+str(id)+'link'+str(i+1)+'\').css(\'display\',\'block\');">Show Next Line of Code</a>'

	showallHTML = '<p id="answer'+str(id)+'shown" style="display:none;"><b>Full Answer:</b></p><div id="showall'+str(id)+'" style="display:none;">'+code+'</div><a id="showall'+str(id)+'link" href="javascript:;" onClick="$(\'#showall'+str(id)+'\').css(\'display\',\'block\');$(\'.linecode'+str(id)+'\').css(\'display\',\'none\');$(\'.linelink'+str(id)+'\').css(\'display\',\'none\');$(\'#showall'+str(id)+'link\').css(\'display\',\'none\');$(\'#answer'+str(id)+'shown\').css(\'display\',\'inline\');">Show Answer</a>'
	return hintHTML+'<br>'+showlineHTML+'<br>'+showallHTML+'<br>'


def makePage(lesson, session, rstudioUser):
	###############################################
	#	K-Nearest Neighbors Pages	      #
	###############################################
	if lesson == 'knn1':
		return '<div class="lesson" id="NPStext"><h2>K-Nearest Neighbor</h2><h3>What is K-Nearest Neighbor?</h3><p>K-Nearest Neighbors (KNN) is a basic classification algorithm, frequently used by data scienctists to identify unclassified items in a dataset. KNN is a lazy (generalizing past the training data is pushed off until a query is made to the system), non-parametric (the data does not belong to a particular distribution) algorithm. KNN works by using euclidean distances to measure distance between data points. There are 2 steps to performing KNN: First, a dataset with known classifications (the "Training Set") is fed into the KNN algorithm. Then, points of unknown classification (the "Test Set") check the classifications of points nearest to them, and are classified accordingly.</p><a href="?lesson=knn2"><div class="arrow" id="forwardArrow"></div></a></div>'
	elif lesson == 'knn2':
		return '<div class="lesson" id="NPStext"><h2>K-Nearest Neighbor</h2><h3>Efficiency</h3><p>To reiterate, KNN is non-parametric and thus makes no assumptions about data distribution. This is useful because real-world data tends to not fall into nice distributions that other algorithms may assume.	Additionally, KNN is lazy, making it a costly algorithm: whenever testing occurs on new data points, KNN needs to use every single training point in order to classify. So, KNN does not cost many computational resources to train a set of data, but testing comes with a higher cost.</p><a href="?lesson=knn1"><div class="arrow" id="backArrow"></div></a><a href="?lesson=knn3"><div class="arrow" id="forwardArrow"></div></a></div>'
	elif lesson == 'knn3':
		return '<div class="lesson" id="NPStext"><h2>K-Nearest Neighbor</h2><h3>Optimizing K</h3><p>First, the K in KNN represents how many neighbors used in order to classify new points. Consider the following image:<br/><br/>  <img src="images/KNN/knnclassification.png" title="Adopted from absoluteastronomy.com" align="left" style="padding: 10px"> In this example, the green circle is a new datapoint and the squares/triangles  are the training data. The solid circle is what to consider when K = 3. The inside of this circle contains the 3 closest neighbors to the new datapoint. There are two triangles and one square so, by majority, the new datapoint is classified as a triangle. Now consider the dotted circle. The dotted line represents K = 5 since there are now 5 neighbors. With three of the neighbors being squares and two being triangles, this time the datapoint is classified as a square. So, as you can see, altering the K value can alter the classification of new, "test" points. <br/><br/>There are tradeoffs for using high and low numbers for K. Low numbers tend to specialize the data and make points over-influential and high numbers tend to broaden the data and make points under-influential. A lot of times, it helps to visualize the data to understand it better. Otherwise, though, the data may require domain expertise in order to make the best decision.</p><div class="container"><a href="?lesson=knn2"><div class="arrow" id="backArrow"></div></a><a href="?lesson=knn4"><div class="arrow" id="forwardArrow"></div></a></div></div>'
	elif lesson == 'knn4':
		return '<div class="lesson" id="NPStext"><h2>K-Nearest Neighbor</h2><h3>Lesson</h3><p>Datasets Required: <a href="datasets/DiabetesTrain.csv">Diabetes Training Set</a>&nbsp;&nbsp;<a href="datasets/DiabetesTest.csv">Diabetes Testing Set</a><br /><br /> Our KNN algorithm utilizes two datasets: a training set and a testing set. You can observe how the test data can vary by manipulating the value of K. Perform the following tasks: <ul><li>You will upload the provided diabetes datasets to Galaxy.</li><li>You will select the KNN tool from the Learn2Mine tools in the left panel of Galaxy.</li><li>Galaxy will prompt you to input a value K and Galaxy will prompt you to select data that you have previously uploaded to Galaxy.</li></ul><br/> Once you have completed running the tool, you will see 2 jobs pop up in the history: KNN (HTML) and KNN (CSV). View the HTML results to see a formatted representation of your results. If you are happy with your classifications, send them to Learn2Mine by using the Submit Data tool in the Learn2Mine toolbox, and selecting the KNN (CSV) output.</p><form target="_blank" action="http://portal.cs.cofc.edu/learn2mine/"> <!-- LINKS TO GALAXY --><input type="submit" value="Try Our First KNN Lesson"></form><a href="?lesson=knn3"><div class="arrow" id="backArrow"></div></a><a href="?lesson=knn5"><div class="arrow" id="forwardArrow"></div></a></div>'
	elif lesson == 'knn5':
		return '<div class="lesson" id="NPStext"><h2>K-Nearest Neighbor</h2><h3>Advanced Lesson</h3><p>Datasets Required: <a href="datasets/DiabetesTrain.csv">Diabetes Training Set</a>&nbsp;&nbsp; <a href="datasets/DiabetesTest.csv">Diabetes Testing Set</a><br /> This next lesson will allow you to earn KNN Mastery, so get ready to do some coding! <br /><br/>You likely received a score in the high 70\'s or low 80\'s in the previous KNN lesson, but now you are going to do better than that. Using the same dataset, we want you to write code in RStudio to figure out how to get a higher KNN score (accuracy). You will not be able to do this by simply changing the value of K. You need to think about the variables for this dataset at hand.<br><br> Some of the variables are likely to explain more about the classification of a data point. One way to factor this in is to multiply the column (or feature) of the dataset by a number. For example, multiplying a feature by 2 yields a KNN classifier that puts 2x weight on that feature. We do not expect you to simply use trial-and-error to figure out what weights will give you a good accuracy. Instead, however, we want you to create an algorithm that will give you the weights that you want to use for each feature. After finding these weights, use our KNN backbone code (access to this is explained in the RStudio tab) to program the weights in. You can then run the KNN classifier using your custom, weighted code and, if your score is good enough, then you will have proven that you have mastered the KNN algorithm. For help creating an algorithm to find these weights for you, see the <a href="?lesson=techniques4">Optimization</a> section in the Techniques Tab.<br><br> Carry out the following steps to earn your KNN Mastery Badge:<ol><li>Log in to RStudio</li><li>Retrieve our KNN code through the git respository(See the "Using RStudio tab" to the right for more details)</li><li>Add weights to the columns of the dataset (this will likely require you to experiment with the data in RStudio first)</li><li>Run your modified code from the KNN tool (choose "Use my KNN R Script")</li><li>Submit your results to Learn2Mine. If you classify more than 85% of the data correctly, then you\'ve mastered the lesson!</li></ol></p><form target="_blank" action="http://portal.cs.cofc.edu/learn2mine/"> <!-- LINKS TO GALAXY --><input type="submit" value="Try Our Advanced KNN Lesson"></form><a href="?lesson=knn4"><div class="arrow" id="backArrow"></div></div>'



	###############################################
	#	        K-Means Pages		      #
	###############################################
	elif lesson == 'kmeans1':
		return '<div class="lesson" id="NPStext"><h2>K-Means Clustering</h2><h3>What is K-Means?</h3><p>Clustering is a useful tool in Data Science that seeks to group points in a dataset into meaningful groups, or "clusters". K-Means is one of the most widely used clustering algorithms, and one that has many different variations. We will be working with one of the more popular versions of the K-means algorithms: Lloyd\'s algorithm. The K-Means algorithm requires an arbitrary (though logically appropriate for the dataset) amount of clusters in order to start. The algorithm first selects random datapoints to be the cluster centers (or centroids). Each other datapoint is then iterated over in order to find the centroid closest to it, and is grouped in that cluster. Once all data points belong to a cluster, new centroids are found and the data is once again iterated over to find their appropriate cluster.<br/><br/> The algorithm may terminate in one of two ways:<br><ol><li>Consecutive iterations of the algorithm produce the same cluster assignments</li><li>A decided maximum number of iterations is reached.</li></ol>All this considered, K-Means is a Non-Deterministic Polynomial Time Hard (np-hard) problem with complexity O(n<sup>fk+1</sup>*log(n)) where f is the amount of features in the dataset, k is the amount of clusters, and n is the amount of datapoints.</p><a href="?lesson=kmeans2"><div class="arrow" id="forwardArrow"></div></a></div>'
	elif lesson == 'kmeans2':
		return '<div class="lesson" id="NPStext"><h2>K-Means Clustering</h2><h3>Illustrated Example</h3><p>Now imagine that you are given a dataset (with three clusters) with the initial cluster centroids already decided. Here the red, blue, and green circles are centroids representative of the three clusters. The next step is to classify each of the grey squares as to being a part of a single cluster, via euclidean distance. From the datapoints (and centroid) a voronoi diagram can be produced (Don\'t worry, this is not part of the lesson). The voronoi diagram shows which datapoints belong to which clusters, indicated by color. Finally, a new centroid for each cluster is calculated from the center of it\'s datapoints, and the process is repeated until termination, as prescribed in "What is K-Means?"<br> <div style="width: 800px"><img src="http://upload.wikimedia.org/wikipedia/commons/5/5e/K_Means_Example_Step_1.svg" title="Step 1: Adopted from Wikimedia" style="float:left; width:200px"/><img src="http://upload.wikimedia.org/wikipedia/commons/a/a5/K_Means_Example_Step_2.svg" title="Step 2: Adopted from Wikimedia" style="float:left; width:200px"/> <img src="http://upload.wikimedia.org/wikipedia/commons/3/3e/K_Means_Example_Step_3.svg" title="Step 3: Adopted from Wikimedia" style="float:left; width:200px"/> <img src="http://upload.wikimedia.org/wikipedia/commons/d/d2/K_Means_Example_Step_4.svg" title="Step 4: Adopted from Wikimedia" style="float:left; width:200px"/></div></p><a href="?lesson=kmeans1"><div class="arrow" id="backArrow"></div></a><a href="?lesson=kmeans3"><div class="arrow" id="forwardArrow"></div></a></div>'
	elif lesson == 'kmeans3':
		return '<div class="lesson" id="NPStext"><h2>K-Means Clustering</h2><h3>Optimizing K</h3><div><img src="http://learn2mine.appspot.com/images/tooFewClusters.png" title="Too Few Clusters" style="float:left; width:300px; padding: 10px 10px 10px 10px"/><img src="http://learn2mine.appspot.com/images/tooManyClusters.png" title="Too Many Clusters" style="float:left; width:300px; padding: 10px 10px 10px 10px"/><p>The goal of K-Means Clustering is to try to group your data while maintaining a balance between number of clusters and the uniformity within those clusters. The more clusters you have, the more specialized they will be. However, more specialized does not necessarily mean better, as having too many clusters can lead to divisions between points that are more similar than not. Therefore, evaluating performance of a K-Means test can be a bit arbitrary, but the test should strive to find an optimal balance between keeping the Sum-Of-Squares Error between clusters high, and the Sum-Of-Squares Error within clusters low.</p><p>As you can see to the left, the image on the left has not begun with enough centroids to accurately cluster the data, and consists of some clusters that make more sense separated into multiple ones. On the other hand, the right hand image has too many clusters, and begins to divide up data that really probably belongs together.<br/>(<b>NOTE:</b> we are able to observe this easily because of the 2 dimensionality of this data. In the real world, your data will contain many more features, and you will not be able to tell the optimal number of clusters just by looking at the data.</p></div></div><a href="?lesson=kmeans2"><div class="arrow" id="backArrow"></div></a><a href="?lesson=kmeans4"><div class="arrow" id="forwardArrow"></div></a></div>'
	elif lesson == 'kmeans4':
		return '<div class="lesson" id="NPStext"><h2>K-Means Clustering</h2><h3>Lesson</h3><p>Dataset Required: <a href="datasets/Quake.csv">Earthquake Data Set</a><br />Using the above dataset containing various attributes of earthquakes, your job for this lesson is to group those earthquakes using K-means clustering algorithm. Load the data into Galaxy, and then run the K-Means tool. You will have the option of choosing your own k (number of clusters) and number of iterations of the algorithm (we recommend leaving the default value). By manipulating these variables, your goal is to create an optimum balance between the Sum-of-Squares Error within clusters (aiming low) and between clusters (aiming high)fall within the right range of both to pass this lesson.</p> <br><br><form target="_blank" action="http://portal.cs.cofc.edu/learn2mine/"> <!-- LINKS TO GALAXY --><input type="submit" value="Try Our First K-Means Lesson"></form></p><a href="?lesson=kmeans3"><div class="arrow" id ="backArrow"></div></div>'


	###############################################
	#	 Scale n' Filter Pages  	      #
	###############################################
	elif lesson == 'sf1':
		return '<div class="lesson" id="NPStext"><h2>Scaling and Filtering</h2><h3>What Is Scaling And Filtering?</h3><p>Now we will be working on performing techniques that will modify data. Often, data will have missing values and outliers or may need to be scaled in order to reduce bias. We are providing you tools that will enable you to delete missing data, delete outliers, and scale data. </p><a href="?lesson=sf2"><div class="arrow" id="forwardArrow"></div></a></div>'
	elif lesson == 'sf2':
		return '<div class="lesson" id="NPStext"><h2>Scaling and Filtering</h2><h3>Dealing With Missing Data</h3><p>Missing data occurs often with datasets for many reasons (such as data involving temperature - someone may forget to record data for a day). Sometimes using the data that is there in lieu of the missing data is still very valuable, but sometimes that data becomes useless without key variables. This will become very apparent in the upcoming lesson. Also, you may have algorithms written in such a way that all the data is required to be present in order to effectively produce meaningful output. </p><a href="?lesson=sf1"><div class="arrow" id="backArrow"></div></a><a href="?lesson=sf3"><div class="arrow" id="forwardArrow"></div></a></div>'
	elif lesson == 'sf3':
		return '<div class="lesson" id="NPStext"><h2>Scaling and Filtering</h2><h3>Dealing With Outliers</h3><p>Outliers are very fickle beings in datasets. There are many beliefs on whether or not excluding outliers is a fair way to modify data, but having the option is important. Our tool will give you the option to exclude outliers based on a z-score (the amount of standard deviations away from the mean a datapoint is). This exclusion is based off of every single feature of a datapoint. So if you select a z-score of 3.0 and the datapoint has a feature that goes over the third standard deviation, then the entire datapoint will be considered an outlier and will be thrown out.</p><a href="?lesson=sf2"><div class="arrow" id="backArrow"></div></a><a href="?lesson=sf4"><div class="arrow" id="forwardArrow"></div></a></div>'
	elif lesson == 'sf4':
		return '<div class="lesson" id="NPStext"><h2>Scaling and Filtering</h2><h3>Normalization</h3><p>Scaling is a way to normalize data. The scale option within our tool will center your data and scale each feature of the dataset, normalizing your data. This will accomplish a reduction in bias. So features will large amounts of variance will not skew data or be over-emphasized in results. Also, scaling assumes you fit the statistical requirements for normalization (typically you need at least 30 datapoints).<br/><br/>It is important to realize that scaling only works for numeric data points, and that Categorical fields within a dataset must be skipped over when scaling data. When you perform our lesson you must remember to tell our Scaling tool not to consider those.</p><a href="?lesson=sf3"><div class="arrow" id="backArrow"></div></a><a href="?lesson=sf5"><div class="arrow" id="forwardArrow"></div></a></div>'
	elif lesson == 'sf5':
		return '<div class="lesson" id="NPStext"><h2>Scaling and Filtering</h2><h3>Lesson</h3><p>Dataset Required: <a href="datasets/Vertebral_Column_2C_MV.csv">Vertebral Column Data Set</a> (Edited)<br /> For this lesson, you\'ll be using a dataset filled with outliers and missing data. Upload the above dataset into Galaxy, then filter it in the following ways: <ul> <li>Delete all data missing 10% or more of their fields</li> <li>Remove any data that contains a field with a z-score of higher than 2.5</li> <li>Scale the data</li> </ul> Other Things to Know: The missing data fields in this set are signified by a question mark (?). In addition, this dataset contains a categorical variable (vertebrae classification located in column 7) be sure to specify this at the bottom, otherwise the filtering tool will try to find the z-score of a categorical variable, which does not make sense! <br /><br /> These are some pretty harsh rules we are weeding through this data by, and in the real world you\'ll want to be more cautious with your datasets. This lesson is just to illustrate the idea of filtering data. </p> <form target="_blank" action="http://portal.cs.cofc.edu/learn2mine/"> <!-- LINKS TO GALAXY --> <input type="submit" value="Try Our Scaling & Filtering Lesson"> </form> <p>(NOTE: The dataset above is a trimmed version of a full dataset, with a few random values deleted from it to fit our purposes. If you\'d like to see the full dataset, you can download it below!)<br /> <a href="datasets/Vertebral_Column_2C.csv">Vertebral Column Data Set (Full)</a></p><a href="?lesson=sf4"><div class="arrow" id="backArrow"></div></a></div>'


	###############################################
	#    Principal Component Analysis Pages	      #
	###############################################
	elif lesson == 'pca1':
		return '<div class="lesson" id="NPStext"><h2>Principal Component Analysis</h2><h3>What Is Principal Component Analysis?</h3><p>Principal Component Analysis (PCA) is a dimensionality reduction technique. You may have noticed the references to "Principal Components" in outputs of your previous lessons. We performed this technique to make it easier to visualize your output. For example, if you did the KNN lesson, then you were working with a problem that would take 7 dimensions to fully visualize, because there are 7 features in the Diabetes dataset. However, by using PCA, we were able to find the 2 fields with the greatest impact on variance (the "Principal Components") so that we could present our results in an easily comprehensible way. Each field in a dataset has some impact on the variance in a dataset, and using PCA, we can find which ones matter most.<br/><br/>Principal Components are measured in terms of their "Percent Variance Explained", and are ordered from highest to lowest, with the "first" principal component being the one that points along the axis of greatest variance. Taking the sum of all of the Principal Components of a dataset will always give you 100%. The goal of PCA is to find which points are most influential to simplify further analysis and visualization of the dataset. So, in practice, you will typically use two principal components for visualization and more for analysis depending upon your problem-at-hand and your dataset. When you visualize your data this way, then your data is projected onto the first two principal components.</p><a href="?lesson=pca2"><div class="arrow" id="forwardArrow"></div></a></div>'
	elif lesson == 'pca2':
		return '<div class="lesson" id="NPStext"><h2>Principal Component Analysis</h2><h3>A Glimpse At The Algorithm</h3><img src="http://learn2mine.appspot.com/images/PCAgraph.png" title="V1 is our First Principal Component, and V2 is the Second" style="height:300px; padding: 10px" align="left"> <p>When finding principal components, a PCA algorithm creates a covariance matrix. This matrix relates each feature with all the other features and itself in order to find the axis with the greatest spread (variance)<sup>1</sup>. After doing this, PCA projects the full data onto the principal components that it is using (amount can vary). At this point, the principal components can be used to visualize the data.<br /><br /> On the left you will see a two-dimensional dataset with correlated variables X and Y. Through PCA they are transformed into the uncorrelated (perpendicular) variables v1 and v2. Points along the v1 axis have a much greater spread than along the v2 axis. Therefore V1 is our first Principal Component, and v2 is our Second. <br/><br/><sub><sup>1</sup>For those with linear algebra experience, the eigenvectors of this matrix point in the direction of the axes with the greatest spread, referred to as principal axes. The eigenvector with the highest eigenvalue is the eigenvector pointing the direction of greatest variance.</sub></p><a href="?lesson=pca1"><div class="arrow" id="backArrow"></div></a><a href="?lesson=pca3"><div class="arrow" id="forwardArrow"></div></a></div>'
	elif lesson == 'pca3':
		return '<div class="lesson" id="NPStext"><h2>Principal Component Analysis</h2><h3>Lesson</h3><p>Dataset Required: <a href="datasets/Quake.csv">Earthquake Data Set</a><br /><br />This lesson will not require a lot of work from you, but, rather, we are asking that you pay a lot of attention to the results and take the meaning away from it. You will be using the Earthquake dataset. There are only four features in this dataset so there will only be four principal components. Pay attention to the file to check if there is a header so you know what to pick for that option in the PCA tool. Upon viewing the html output of PCA, you will see an output that consists of the "Percent Variance Explained" by each principal component (these will total to 100 if you add them as we are showing you every principal component).<br /><br /> Following this, we give you the standard deviations (<span style="white-space: nowrap">&radic;<span style="text-decoration:overline;">&nbsp;Variance&nbsp;</span></span>) of each component. Lastly, we output a screeplot - a way to view the percent variance explained for the principal components graphically. In order for us to make sure you followed the instructions and performed PCA correctly, we output a second file, much like in the other lessons, for you to submit to us using the "Submit to Learn2Mine" tool.<br/><br/>Note: For future reference, this PCA tool cannot handle missing data as it turns all the data into factors. If you use data that has missing points, make sure you Scale and Filter it before you run PCA on it.</p><form target="_blank" action="http://portal.cs.cofc.edu/learn2mine/"> <!-- LINKS TO GALAXY --><input type="submit" value="Try Our PCA Lesson"></form><a href="?lesson=pca2"><div class="arrow" id="backArrow"></div></a></div>'


	###############################################
	#   Partial Least Squares Regression Pages    #
	###############################################
	elif lesson == 'pls1':
		return '<div class="lesson" id="NPStext"><h2>Partial Least Squares Regression</h2><h3>What is Regression?</h3><img src="http://upload.wikimedia.org/wikipedia/commons/3/3a/Linear_regression.svg" title="Adopted from http://upload.wikimedia.org/wikipedia/commons/3/3a/Linear_regression.svg" style="height:300px; padding: 10px" align="right"><p>Regression is a statistical technique which predicts a response (dependent variable) from given features (independent/predictor variables). There are a multitude of regression techniques. In Statistics classes you typically will learn the Ordinary Least Squares model of regression, which minimizes the sum of squared distances between the regression model and actual datapoints (minimizes the residual). <br><br>The purpose of regression is making a prediction conditioned by the features of the dataset. As data scientists, we would like to work with a powerful form of regression. We will be using Partial Least Squares Regression.</p><a href="?lesson=pls2"><div class="arrow" id="forwardArrow"></div></a></div>'
	elif lesson == 'pls2':
		return '<div class="lesson" id="NPStext"><h2>Partial Least Squares Regression</h2><h3>Partial Least Squares Regression</h3><p>Partial Least Squares Regression (PLS) finds a linear regression model by projecting the predictor features and the response into a new space. A PLS model will look into this new space and attempt to find the direction in the feature space that explains the maximum variance direction of the response space. This is all done in multiple dimensions and it is a lot simpler to think about PLS as applying PCA techniques to the features of regression. <br><br>PLS is tailored to work in a starkly different manner than typical regression models - it functions better whenever there are more features than datapoints and when there exists multicollinearity between the features. This is because PLS utilizes not only observed variables (directly measured), but also <a href="http://en.wikipedia.org/wiki/Latent_variable" target="_blank">latent variables</a>. These latent variables are not directly measured, but rather are pseudo-observed variables because they are inferred from the observed variables. So one of the tradeoffs that PLS receives is that the data\'s dimensionality is significantly less than it could be due to the use of the latent variables.<br /><br />For more detailed information, see this <a href="http://en.wikipedia.org/wiki/Partial_least_squares_regression" target="_blank">article</a></p><a href="?lesson=pls1"><div class="arrow" id="backArrow"></div></a><a href="?lesson=pls3"><div class="arrow" id="forwardArrow"></div></a></div>'
	elif lesson == 'pls3':
		return '<div class="lesson" id="NPStext"><h2>Partial Least Squares Regression</h2><h3>Partial Least Squares Regression</h3><p>Dataset Required: <a href="datasets/Basketball.csv">Basketball Dataset</a><br />For this next lesson, we want you to predict the amount of shots that a basketball player makes per minute, based upon a player''s assists per minute, height (in cm), age, and time played. We are providing you with a full dataset. The PLS tool asks you how much of your data you want to turn into testing data. Keep in mind that you do not want to get rid of too much data as to make your regression model really weak, but you also do not want to overtrain and leave yourself with nothing for which to test. Our grader for this lesson takes into account how much data you used for testing, so keep that in mind when deciding. <br><br>Your goal is to reduce the mean squared error of the residuals of the test data matched against your trained regression model. For this lesson, we want you to select the \"Leave-One-Out\" evaluation technique. This is so that we can standardize your scores and not have to handle the subtle differences between the results produced from these techniques. For your own knowledge, though, 10-fold cross validation divides the data into ten segments and evaluates your model based upon 10% of the data and Leave-One-Out cross validation leaves on test point out to evaluate your regression model. These evaluation techniques run multiple times to reinforce your model''s strength.</p><form target="_blank" action="http://portal.cs.cofc.edu/learn2mine/"> <!-- LINKS TO GALAXY --><input type="submit" value="Try Our PLS Lesson"></form><p>More information on our PLS implementation available <a href="http://www.jstatsoft.org/v18/i02/paper" target="_blank">here</a></p><a href="?lesson=pls2"><div class="arrow" id="backArrow"></div></a></div>'


	###############################################
	#	"Getting Started" Pages		      #
	###############################################
	elif lesson == 'welcome1':
		return '<div class="lesson" id="NPStext"><h2>Getting Started</h2><h3>Welcome</h3><p>Welcome to Learn2Mine, an Open-Source Cloud-Based Informatics Platform For Integrated Teaching and Data Exploration. Learn2Mine is a one-stop shop for analyzing and making sense of data, as well as for learning the techniques that give life and meaning to big data.</p><a href="?lesson=welcome2"><div class="arrow" id="forwardArrow"></div></a></div>'
	elif lesson == 'welcome2':
		return '<div class="lesson" id="NPStext"><h2>Getting Started</h2><h3>Lessons</h3><p>Every technique that we offer will have an associative lesson with it (sometimes there will be more than one). Sometimes the lessons are as trivial as figuring out an optimal heuristic (just a number) for an algorithm with data provided to you, while lessons, other times, could involve writing code for an algorithm. Whenever you complete a lesson, you will have a score associated with what you did. This score is how we grade whether or not you pass a lesson, as well as being a way for us to rank you against others doing the same lesson.</p><a href="?lesson=welcome1"><div class="arrow" id="backArrow"></div></a><a href="?lesson=welcome3"><div class="arrow" id="forwardArrow"></div></a></div>'
	elif lesson == 'welcome3':
		return '<div class="lesson" id="NPStext"><h2>Getting Started</h2><h3>Skill Tree and Leaderboards</h3><div align="right" style="width:25%; float:right;"><img src="images/locked.png" style="height:75px; padding-right:20px; padding-left:20px; padding-bottom:20px;"/><img src="images/stillneedswork.png" style="height:75px; padding-right:20px; padding-left:20px; padding-bottom:20px;"/><img src="images/learned.png" style="height:75px; padding-right:20px; padding-left:20px; padding-bottom:20px;"/><img src="images/mastered.png" style="height:75px; padding-right:20px; padding-left:20px; padding-bottom:20px;"/></div><p>Each user has a skill tree that keeps track of their progress. This skill tree is located in the Profile section of the site. Initially, you will not have access to a lot of the techniques that we have to offer. This is done in such a way that you will learn the simpler techniques first - lesson difficulty also follows a very similar manner.<br /><br /> In your skill tree, when you do not have access to a technique, then that technique shows up as locked (red), when you have access to a technique, but have not completed the lesson for that method, then that technique shows up as still needs work (yellow). Whenever you have completed and passed the lesson for a technique, then it will show up as learned (green). When you have shown exceptional mastery of the technique then it will show up as mastered (blue). Sometimes technique mastery may require you to undergo lessons where you customize algorithms in order to improve or expand upon their functionality.<br /><br />Finally, when you complete a lesson, your score is then recorded for grading. In addition to grading your score is also used to rank you against other people that have completed that same lesson. In the leaderboards section of the site, you can check the leaderboards for each of the lessons. We keep track of the top 10 scores for each lesson.</p><a href="?lesson=welcome2"><div class="arrow" id="backArrow"></div></a><a href="?lesson=welcome4"><div class="arrow" id="forwardArrow"></div></a></div>'
	elif lesson == 'welcome4':
		return '<div class="lesson" id="NPStext"><h2>Getting Started</h2><h3>Open Badges</h3><p>During your progression here you will be able to earn badges in order to show off your progress within Learn2Mine and on your own site. We implement Mozilla\'s <a href="http://openbadges.org/">Open Badges</a>. Open Badges allows you to collect badges from a multitude of academic services on the Web. Once you start earning badges, you will be able to access them in your <a href="http://backpack.openbadges.org/backpack">backpack</a>. To view your Learn2Mine badges within our site, you will need to create a "Collection" named "Learn2Mine" on the backpack site. Unfortunately, you cannot create a collection until you have earned at least one badge. Also, you will need to tick the checkbox that makes your collection public, otherwise we will not have access to your badges for displaying purposes. Typically, badges will represented remarkable success in learning algorithms and data science techniques here.</p><br/><img id="openBadgesImg" align="center" src="https://s3.amazonaws.com/kinlane-productions/api-evangelist/mozilla-open-badges/mozilla-open-badges.png" align="left" style="padding-right:20px"/></div><a href="?lesson=welcome3"><div class="arrow" id="backArrow"></div></a></div>'


	###############################################
	#		Using Galaxy Pages	      #
	###############################################
	elif lesson == 'galaxy1':
		return '<div class="lesson" id="NPStext"><h2>Using Galaxy</h2><h3>Uploading Data</h3><p><img src="images/uploadData.png" align="left" style="height:350px; padding-right:20px"/>Galaxy is our back-end framework for Learn2Mine, it\'s where you will be performing your various mining tasks. When you are going through lessons you will be required to upload data we have provided you in order to perform various analyses. This is a very simple proceedure! On the left-hand side of your Galaxy window is a list of tools that you can use. Right now we will be focusing on the "Get Data" toolset. Once you have clicked "Get Data" you will have the option to upload a file from your computer and this iplss when you would submit the files you received from Learn2Mine. When you have submitted these files, they will appear on the right-hand side of Galaxy as "jobs." Typically, you should not need to specify a datatype as Galaxy will auto-select the correct format. Files that are uploading to Galaxy appear as blue whenever they are in the process of being uploaded, and green once they have finished.</p><a href="?lesson=galaxy2"><div class="arrow" id="forwardArrow"></div></a></div>'
	elif lesson == 'galaxy2':
		return '<div class="lesson" id="NPStext"><h2>Using Galaxy</h2><h3>Using Our Tools</h3><p><img src="images/ourTools.png" align="left" style="padding-right:20px; height:350px"/>As you likely saw whenever you navigated to the "Get Data" toolset there is a special set of tools that we have created for your use. When you open up the "Learn2Mine Toolset" you will see a list of algorithms and a few other specialized tools. The algorithm-specific tools are discussed in each of their sections here on the Lessons page. Right now we will focus on the other tools to further your understanding of Galaxy and our integration with it. <br /><br />The "Submit To Learn2Mine" tool is how you will actually pass information from Galaxy to Learn2Mine. This tool will ask you for the key you created (this will be explained in the next section), the algorithm output file, and the type of grading you want conducted. The type of grading you want conducted comes straight from the lesson you are undergoing. For example, you would use the K-Means Grader if you were conducting a lesson on the K-Means algorithm.<br /><br />Lastly, we have extra descriptions how to use our tools and common mistakes at the bottom of each tool\'s input page.</p><a href="?lesson=galaxy1"><div class="arrow" id="backArrow"></div></a><a href="?lesson=galaxy3"><div class="arrow" id="forwardArrow"></div></a></div>'
	elif lesson == 'galaxy3':
		return '<div class="lesson" id="NPStext"><h2>Using Galaxy</h2><h3>Using The Job History</h3><p><img src="images/history.png" align="left" style="padding-right:20px; width:200px"/>Galaxy keeps track of all of your pst jobs through the "History" on the right hand side of the window. \"Jobs\" listed in this History can be viewed at any time by clicking the eye icon in the top right corner. Alternatively, any output existing in your history can be used as input for another tool you with to run. For example, when you use the "Create Key" tool, a "Key" job will show up in your history. When submitting other files to Learn2Mine, you will pass in this Key output, along with the output of another Job for grading.<br><br> Most of Learn2Mine\'s tools create 2 Jobs in the history:<ol style="padding-left:275px"><li>A CSV results file, for our grading purposes</li><li>A HTML file, with the results of your analysis.</li></ol>The HTML will be the only really meaningful item for your purposes. Click the eye icon to see what the algorithm you performed did.</p><a href="?lesson=galaxy2"><div class="arrow" id="backArrow"></div></a><a href="?lesson=galaxy4"><div class="arrow" id="forwardArrow"></div></a></div>'
	elif lesson == 'galaxy4':
		return '<div class="lesson" id="NPStext"><h2>Using Galaxy</h2><h3>Your Key</h3><p>The "Create Learn2Mine Key" tool is vital for keeping track of your progress. We use this key in order to persist your results and score so that we can store your success in our database, as well as giving you access to new tools and adding you to our leaderboards. This key is uniquely generated whenever you first sign in to Learn2Mine. The "Create Learn2Mine Key" tool asks for your key for these reasons and you can find your unique key below. Please do not share your key with anyone else as it is how you are uniquely identified.<br /></p><p>Your Key:'+str(session)+'</p><!--Pulled from LessonHandler in main.py to give user\'s their Galaxy key --><p>Feel like your key has been compromised? <a href="/newKey">Generate a new one</a>. <br>(<b>NOTE:</b>) You will need to recreate your key with the "Create Learn2Mine Key" tool in Galaxy after doing this.</p><a href="?lesson=galaxy3"><div class="arrow" id="backArrow"></div></a><a href="?lesson=galaxy5"><div class="arrow" id="forwardArrow"></div></a></div>'
	elif lesson == 'galaxy5':
		return '<div class="lesson" id="NPStext"><h2>Using Galaxy</h2><h3>Your First Lesson</h3><p>Dataset Required: <a href="datasets/DiabetesTrain.csv">Diabetes Training Dataset</a><br />Before we dive in to learning the intricacies of data science, we have to make sure you understand how to use this software. To do this, we have prepared a short, introductory lesson to start you off. Perform the following steps to complete this lesson:<br/><ol><li>Upload the Diabetes Dataset to Galaxy</li><li>Use your appropriate key (from the previous page, or the "My Logins" tab on the right") to make a key.</li><li>Use the uploaded Dataset, and your Key as inputs for the Submit to Learn2Mine tool</li></ol>If completed successfully, you will be able to view your html output on the \"Submit to Learn2Mine\" tool and see that you have \'learned\' this introductory lesson. Viewing your profile after this will show you all the skills you have unlocked.</p><form target="_blank" action="http://portal.cs.cofc.edu/learn2mine/"> <!-- LINKS TO GALAXY --><input type="submit" value="Try Our Tutorial Lesson"> </form><a href="?lesson=galaxy4"><div class = "arrow" id ="backArrow"></div></a><a href="?lesson=galaxy6"><div class = "arrow" id ="forwardArrow"></div></a></div>'
	elif lesson == 'galaxy6':
		return '<div class="lesson" id="NPStext"><h2>Using Galaxy</h2><h3>FAQs</h3><p><b>My job seems to be running forever &lt;-</b> Usually just restarting the job or conducting a different job will push the job through and finish it. The only time you might have to exit the job and completely retry it is when using the upload data tool. Signs of this typically include jobs being hung up whilst they are colored blue (unique to upload data) or grey (job not running).<br/><br/><b>My job stays yellow (working) even though it should have been done a lot faster &lt;-</b> You may have to click the refresh history button at the top of the right panel. Galaxy occassionally will stop refreshing your history so this would be a temporary workaround.</p><a href="?lesson=galaxy5"><div class="arrow" id="backArrow"></div></a></div>'


	###############################################
	#		Using RStudio		      #
	###############################################
	elif lesson == 'rstudio1':
		return '<div class="lesson" id="NPStext"><h2>Using RStudio</h2><h3>What Is R?</h3><p>R is a programming language that is specialized for the implementation of statistics and modeling. R is open-source and runs on a multitude of platforms. There are many free packages and suites within R and there are even more available libraries that have a large, dedicated group of developers. The algorithms in our lessons are coded in R and whenever you start customizing and running your own code it will also be in R. <br /><br /> For more information, please visit <a href="http://www.r-project.org/">R-Project</a><br/> In addition, for help learning and practicing the basics of R programming, try <a href="http://www.codeschool.com/courses/try-r">http://www.codeschool.com/courses/try-r</a></p><a href="?lesson=rstudio2"><div class="arrow" id="forwardArrow"></div></a></div>'
	elif lesson == 'rstudio2':
		return '<div class="lesson" id="NPStext"><h2>Using RStudio</h2><h3>What Is RStudio?</h3><p>RStudio is an IDE (integrated development environment) for modifying and executing R code. We have our own instance of RStudio on our server and you will be able to log in to RStudio and run code on the fly. The IDE has its own output frame so you will not have to install any dependencies for RStudio to work on your machine since it is handled entirely in the cloud. In RStudio, you will be able to write and save your own RScripts, or modify some of ours to see if you can master the Data Mining techniques by improving our tools\' results.<br /><br />RStudio is linked to users on our server, meaning you will be given your own home directory within which you can organize and save your R code however you wish. All you have to do to set yourself up as a user on the server is run the "Key Tool" in galaxy with your email address and key as it has been given to you. From then on, you will be able to log in to your RStudio account using that information as your username and password, respectively.<br><br>For more information on RStudio, please visit <a href="http://www.rstudio.com/about/">their website</a></p><a href="?lesson=rstudio1"><div class="arrow" id="backArrow"></div></a><a href="?lesson=rstudio3"><div class="arrow" id="forwardArrow"></div></a></div>'
	elif lesson == 'rstudio3':
		return '<div class="lesson" id="NPStext"><h2>Using RStudio</h2><h3>Prerequisites for Custom Code</h3><p>We have created a git repository that contains framework code that we aim for you, our users, to modify in order to demonstrate topic mastery. When you are ready to try your hand at coding in RStudio you will probably want to start by grabbing and examining the code we have prepared for you. That code can be retrived through Git by following these steps: <ol><li>From the menu bar, select "Project"</li><li>Now Select "Create Project"</li><li>From there you will select "Version Control" and then "Git."</li> <li>In the "Repository URL you will enter: "https://bitbucket.org/Learn2Mine/rstudio-code.git"</li></ol>The other options are for use by you. Your project directory will be important for transferring information back to Learn2Mine.</p><a href="?lesson=rstudio2"><div class="arrow" id="backArrow"></div></a><a href="?lesson=rstudio4"><div class="arrow" id="forwardArrow"></div></a></div>'
	elif lesson == 'rstudio4':
		return '<div class="lesson" id="NPStext"><h2>Using RStudio</h2><h3>Custom Code & Modifications</h3><p>Once you have created some custom code, you will want to send files back to Learn2Mine for grading. For example, if you customized a K-Nearest Neighbor classifier and you want to submit it for grading, then you will go to the KNN tool in Galaxy and select "Yes" on the custom code radio button. After this, you will be required to input the path to your custom KNN file. Your file, however, will have been saved on our server. This server utilizes your username for RStudio and the directory you need to key in will look as follows: <b>'+str(rstudioUser)+'</b>/path/to/project/myCustomFile.R</p> <p>NOTE: Our tools look for an output in the form of a csv file called "results.csv"; so write what you want to send to galaxy in one such file (see our code for examples). If you do not write to a "results.csv", Galaxy will randomly pick a different ".csv" file you do write to, with apparent favoritism that we do not understand. Just use "results.csv".</p><a href="?lesson=rstudio3"><div class="arrow" id="backArrow"></div></a><a href="?lesson=rstudio5"><div class="arrow" id="forwardArrow"></div></a></div>'
	elif lesson == 'rstudio5':
		return '<div class="lesson" id="NPStext"><h2>Using RStudio</h2><h3>Your Authentication</h3><p>Here we provide you with authentication information for you to use our server instance of RStudio. Your username is based upon your Google account and your password is based upon your unique key that you used in Galaxy. <br /><br />Username: '+str(rstudioUser)+'<br />Password: '+str(session)+'</p><!--Pulled from LessonHandler in main.py to give user\'s their RStudio Info --> <p><a href="learn2mineserver:8787">Link to RStudio</a></p><a href="?lesson=rstudio4"><div class="arrow" id="backArrow"></div></a></div>'


	###############################################
	#		Techniques Pages	      #
	###############################################
	elif lesson == 'techniques1':
		return '<div class="lesson" id="NPStext"><h2>Data Mining Techniques</h2><h3>Learning</h3><p>Data comes in many different flavors. Sometimes you will have data that you are very familiar with and you want to use that data in order to learn about new data you collect. Other times you may have lots of useful data, but it is difficult to determine what in the data is even meaningful. Regardless of the type of data you collect, there will always be different algorithmic approaches in order to make sense and learn from the data. Here we will discuss the two main approaches to machine learning.</p><a href="?lesson=techniques2"><div class="arrow" id="forwardArrow"></div></a></div>'
	elif lesson == 'techniques2':
		return '<div class="lesson" id="NPStext"><h2>Data Mining Techniques</h2><h3>Supervised Learning</h3><p>Supervised Learning is a type of learning that encompasses algorithms and techniques where you are presented with training data for which you know the correct classification. This training data is used to create a generalization for new, testing data. If the training data is \'trained\' well, then the training set will be able to generalize and classify unknown data with a minimal error rate. There are techniques that handle working with different types of data (i.e. continuous vs categorical); some algorithms can handle all types and others may specialize and only work with one type.</p><h3>Unsupervised Learning</h3><p>Unsupervised Learning, sometimes called density estimation, is a type of learning where correct classifications, or responses, are not given. This does away with the idea of training and testing data as seen in supervised learning. The goal of unsupervised learning is to group data together based on similarities, commonly done through clustering algorithms.</p><a href="?lesson=techniques1"><div class="arrow" id="backArrow"></div></a><a href="?lesson=techniques3"><div class="arrow" id="forwardArrow"></div></a></div>'
	elif lesson == 'techniques3':
		return '<div class="lesson" id="NPStext"><h2>Data Mining Techniques</h2><h3>Optimization</h3><p>In many advanced lessons here you will be presented with a problem that needs optimizing. For example, in the first advanced lesson (For K-Nearest Neighbors) you are required to weight features of a dataset in order to create an improved solution. Oftentimes brute-forcing a solution might not even be possible or could be more hassle than it is worth. Instead, tackling a problem like this can be handled with optimization techniques. Optimization techniques tend to find a great solution, but not necessarily the best solution - and that is perfectly fine. Techniques you might want to research in order to conduct optimization include Hill Climbing, <a href="http://cran.r-project.org/web/packages/GenSA/GenSA.pdf" target="_blank">Simulated Annealing</a>, and <a href="http://cran.r-project.org/web/packages/GA/GA.pdf" target="_blank">Genetic Algorithms</a>. We recommend the use of the GA package for R as it is what we utilized to optimize our KNN classifier and Genetic Algorithms, while more complex, are very powerful techniques once you understand how to use them.</p><a href="?lesson=techniques2"><div class="arrow" id="backArrow"></div></a></div>'


	###############################################
	#	Market Basket Analysis Pages	      #
	###############################################
	elif lesson == 'mb1':
		return '<div class="lesson" id="NPStext"><h2>Market-Basket Analysis</h2><h3>What Is Market-Basket Analysis?</h3><p>Also a form of association rule mining, market-basket analysis (MBA) is an unsupervised clustering algorithm. The basic idea of MBA is that if you buy a set of items (or even no items), then you are more likely to buy another, specific item. For example, if you buy soap and shampoo, then you might have a high affinity for also purchasing conditioner. MBA can also be utilized with credit card purchase analysis, telephone calling patterns, identifying fraud, predicting attributes of peoples, etc. MBA would allow you to create a confidence level about this "rule" you just created.</p><a href="?lesson=mb2"><div class="arrow" id="forwardArrow"></div></a></div>'
	elif lesson == 'mb2':
		return '<div class="lesson" id="NPStext"><h2>Market-Basket Analysis</h2><h3>The Creation of Rules</h3><p>The main result of MBA is the creation of the rules. One common goal of MBA is to be able to predict what items customers will buy in conjunction with others. With this knowledge, retailers could potentially run a sale on one item to boost the sales of a non-sale item. However, MBA is not just used with the purchasing of items, as the name makes it seem, and can be used to mine patterns in a variety of other fields.<br /><br /> Market Basket Analysis looks at general trends in commonly linked fields in a data set to create a set of "Rules" that attempt to predict future entries. The strength and number of these rules depend on several variables that can be controlled when running these algorithms. When it comes to MBA, you need to have knowledge of the dataset that you are working with - this domain level of expertise will reduce the amount of trial and error you may find yourself conducting. Without domain expertise, though, it is very simple to figure out what kind of rules your dataset will make, as you will see in your upcoming lesson. On the next page we will introduce you to the different ways you can place constraints on rules and what kind of impact those constraints will create.</p><a href="?lesson=mb1"><div class="arrow" id="backArrow"></div></a><a href="?lesson=mb3"><div class="arrow" id="forwardArrow"></div></a></div>'
	elif lesson == 'mb3':
		return '<div class="lesson" id="NPStext"><h2>Market-Basket Analysis</h2><h3>Constraints</h3><p><b>Example Rule:</b> {item A, item B} => {item Z}<br/><br/>A rule, following the above format, is created based on a confidence level, a support value, and a given number of features<br/><br/><b>Confidence:</b> The conditional probability that the consequent will be purchased given the antecedents (antecedent is the left-hand side of the rule, while the consequent is the right-hand side of the rule). This simply means that the confidence that you will buy item Z, given the above rule is P(item Z | item A, item B). In layman\'s terms, the confidence of item Z is equivalent to the probability of item Z given the product of the probabilities of items A and B. Confidence defines how strongly your rule holds for the data. For example, a 90% confidence would mean that every time you buy items A and B, then you also buy item Z 90% of the time. A high confidence value is usually preferable, but could also yield redundancy. For example, your algorithm may return the example rule, but also have a rule specifying {item A, item Z} => {item B}. Be careful not to immeadiately disreguard these rules, as they may hold some non-obvious meaning.<br/><br/><b>Support:</b> Unlike confidence, support focuses only on the antecedent of the rule. A support of 10% would be indicative of item A and item B occurring together 10% of the time. In other words, support is equivalent to the probability of the antecedent being true. Raising the minimum support value can limit overly-conclusive outlier rules <br/>(<i>for example: if only one person buys oranges, jam, and toothpaste, then {oranges, jam}=>{toothpaste} has a confidence of 100%, but that does not make it meaningful</i>). <br/>We allow a minimum support value of .001, but that is extremely low and should be avoided for typical usage.<br/><br/><b>Features to Create a Rule:</b> We allow you to specify the amount of features you want to require to create a rule. We have a slightly different number mapping than you might expect when doing this, however. If you input 1, then rules can be created with no features. This is because the empty set is considered a feature when creating rules. If you want to require at least 3 items (excluding the empty set) to create a rule, then you would input 4. Inputting numbers that are too large (either not enough items for a transaction, or no rules could get created due to other constraints), then errors and/or warnings are likely to arise.<br/>For more information see this <a href="http://www.ms.unimelb.edu.au/~odj/Teaching/dm/1%20Association%20Rules%2008.pdf">page</a></p><a href="?lesson=mb2"><div class="arrow" class="arrow" id="backArrow"></div></a><a href="?lesson=mb4"><div class="arrow" class="arrow" id="forwardArrow"></div></a></div>'
	elif lesson == 'mb4':
		return '<div class="lesson" id="NPStext"><h2>Market-Basket Analysis</h2><h3>The Apriori Algorithm and Lift</h3><p>Our MBA tool utilizes the apriori algorithm for frequent itemset mining. Our tool\'s inputs and outputs are centered around this algorithm because it is the heart of MBA; it iterates in a breadth-first search manner while using a hashed tree structure in order to efficiently keep track of potential rules. When you create rules with the apriori algorithm, we believe it is very meaningful to give you output that tells you your best rules. In order to qualify which rules are "best" we utilize <b>Lift</b> in order to decide which rules are the best. So you have learned that high confidence and high support can be very great when detailing rules, but it is not enough. Lift is a method of representing information gain (or improvement) by having a rule. If your lift is over 1, then that means the rule is significant. High lift corresponds to a high positive correlation. This is beneficial because lift considers the antecedent and consequent. For those wondering, lift is defined as: <br/><br/> Lift = support(rule) / (support(antecedent) * support(consequent)).<br/><br/>For more information on the apriori algorithm, see this <a href="http://en.wikipedia.org/wiki/Apriori_algorithm">article</a></p><a href="?lesson=mb3"><div class="arrow" class="arrow" id="backArrow"></div></a><a href="?lesson=mb5"><div class="arrow" class="arrow" id="forwardArrow"></div></a></div>'
	elif lesson == 'mb5':
		return '<div class="lesson" id="NPStext"><h2>Market-Basket Analysis</h2><h3>Types Of Graphical Output</h3><p>Market Basket Analysis allows many different ways to visually represent the rules it creates. Below are descriptions of the 4 types we offer in our tool on Galaxy.<br/><br/><b>Scatterplot:</b> A scatterplot which contains a point for each rule created. The plot is created with support on the x-axis, lift on the y-axis, and shading according to confidence. Scaling is done automatically in accordance with your data. Scatterplots are made for large rulesets.<br/><br/><b>Graphical Matrix:</b> A graphical matrix which reorders rows and columns in order to present similar parts of the data together. Graphical matrices are made for medium-sized rulesets.<br/><br/><b>Grouped Matrix:</b> A grouped matrix nests a lot of interesting facts about the data within its representation. The LHS dimension of the dataset is formatted as follows "X (Feature + Y)" where X is the amount of rules that contain this feature, Feature matches up to a feature from the dataset you were working with, and Y maps to the actual plot itself. The matching item (containing a visual datapoint at the intersection) in the RHS can be represented the antecedent or consequent (different parts of the rule expression) up to Y times for the X rules. Grouped matrices are made for large rulesets.<br/><br/><b>Parallel Coordinates Plot:</b> A parallel coordinates plot is designed to view multi-dimensional data. Each dimension is displayed on its own on the x-axis and the y-axis shares dimensionalities. Arrows on this graph go as far as their rule is long (the more items in a rule, the longer the arrow). Parallel coordinates plots are made for small datasets. If you select this as your graphical output when you have a large ruleset, then the job could take over 20x as long to complete, so please be wary of the plot type you utilize.</p><a href="?lesson=mb4"><div class="arrow" id ="backArrow"></div></a><a href="?lesson=mb6"><div class="arrow" id ="forwardArrow"></div></a></div>'
	elif lesson == 'mb6':
		return '<div class="lesson" id="NPStext"><h2>Market-Basket Analysis</h2><h3>Lesson</h3><p>Dataset Required: <a href="datasets/AdultFiltered.csv">Human Dataset</a><br />For this lesson, you will be working with a dataset from the R package "ARules." This is the package that we are using to conduct MBA (ARules ~ Association Rules). The dataset provided is one where we have discretized most of the data. You will have to keep data manipulation in mind when preparing to conduct MBA, to perform the task, the data cannot have any categorical columns (which the dataset we have given you contains). Also, the file is a "Full Vector" format (this is important for using the tool). See the Galaxy help documentation at the bottom of the tool for more information. When conducting MBA, we want you to allow variables to occur with each other at least 30% of the time. Additionally, we want you to have the rules created in such a way that you are at least 60% sure of the validity of the rules created. Ultimately, this lesson is wanting you to manipulate MBA so that you have at least 150 rules, but no more than 500 rules. <br/><br/>This lesson will probably take you a few tries, but you will know if you passed if you meet these specifications so there is no need to constantly use the Submit to Learn2Mine tool. If you need a hint, however, try submitting to Learn2Mine then checking the Submit tool\'s output.</p><form target="_blank" action="http://portal.cs.cofc.edu/learn2mine/"> <!-- LINKS TO GALAXY --><input type="submit" value="Try Our Market-Basket Analysis Lesson"> </form><a href="?lesson=mb5"><div class="arrow" id ="backArrow"></div></a></div>'



	###############################################
	#	    Neural Networks Pages	      #
	###############################################
	elif lesson == 'nn1':
		return '<div class="lesson" id="NPStext"><h2>Neural Networks</h2><h3>What Are Neural Networks?</h3><img src="/images/NNexample.png" align="right" style="padding: 10px"><p>Neural Networks (NN), or Multilayer Perceptrons, can be used for classification, prediction, and noise reduction. Our primary NN tool is suited for prediction (but we provide you code so you can retool it if you so desire). To the right is an example of a NN created with our tool. Each vertical column of nodes (the circles) are referred to as a layer. The left-most layer is uniquely referenced as the input layer while the right-most layer is uniquely referenced as the output layer. <br /><br />A NN can be simply thought of as a unique form of regression. It takes in a group of inputs and creates a numeric response (prediction-only). Each predictor in this example are inputs to nodes. The nodes then contain that input value - this is done on a row-by-row basis. These nodes then output to the next layer of nodes. The arrows are each associated with a number. These numbers are weights. These weights are generated by the specific version of neural network algorithm conducted. For us, it is just important to know that these weights are updated with every training run of the NN (more on this later). For example, when using predictor.1 you would multiply it by 8.95311 and add it to the top node in the next layer. Repeat this for every predictor and every node in the next layer. You add up all the weighted results and that becomes the value for the respective node.</p><a href="?lesson=nn2"><div class="arrow" id ="forwardArrow"></div></a></div>'
	elif lesson == 'nn2':
		return '<div class="lesson" id="NPStext"><h2>Neural Networks</h2><h3>Bias and Response</h3><img src="/images/NNexample.png" align="right" style="padding: 10px"><p>So you now have populated values for each of the layer\'s nodes. If you notice, though, we have made no mention of the blue arrows that are feeding into these nodes. The blue nodes and arrows are referred to as \'bias\' nodes. The bias nodes are fitted with either 1 or -1 as an input (our implementation uses 1). In NNs, bias is useful because it can shift the entire NN in a horizontal direction (useful for mapping specific input results). In prediction NNs, this is much like fixing the y-intercept in a 2-D regression problem.<br/><br/>There also exists a bias input for the very last node in the NN. The nodes from the penultimate layer are coupled with the last bias node in order to achieve a numeric result from the output layer. This numeric result is referred to as the response of the NN. In other NNs, this is not necessarily a numeric output.</p><a href="?lesson=nn1"><div class="arrow" id ="backArrow"></div></a><a href="?lesson=nn3"><div class="arrow" id ="forwardArrow"></div></a></div>'
	elif lesson == 'nn3':
		return '<div class="lesson" id="NPStext"><h2>Neural Networks</h2><h3>How Do You Affect The Network?</h3><img src="/images/NNHiddenLayersExample.png" align="right" style="padding: 10px; width: 600px;"><p>Our tool gives you two ways to affect the NN that you are creating. First, you can edit the amount of repetitions your NN undergoes. This means full training of your NN for the amount of times you have repetitions. We give you the results of each of the NNs, but we will only plot the best NN for you to see. We impose an upper limit of 10 on the repetitions so our servers are not running wild with NNs. Second, we allow you to control the amount of \'hidden\' layers that you use. Previously, we have been referring to these as "the second layer" because that is what it was in the example. It turns out that you can have as many of these in-between layers as you desire. The layers are referred to as being hidden because you do not actually see what their results are when you perform the algorithm. You know what is input and what is output (the outside-most layers). <br/><br/>You can represent any function with only two hidden layers (though the number of nodes could grow astronomically), but it may be preferable to use more or less, depending on your data. If you wanted to use the amount of hidden layers you see in the example, in our tool on Galaxy you would input as follows: "2,4,3". This is because you want three hidden layers, so you have three values. Each number represents the amount of nodes you wish to have in that layer. In this example, the first hidden layer has 2 nodes, the second has 4 nodes, and the third has 3 nodes. These values do not include the bias node since that is automatically occurring with a hidden layer.</p><a href="?lesson=nn2"><div class = "arrow" id ="backArrow"></div></a><a href="?lesson=nn4"><div class = "arrow" id ="forwardArrow"></div></a></div>'
	elif lesson == 'nn4':
		return '<div class="lesson" id="NPStext"><h2>Neural Networks</h2><h3>Error and Steps</h3><img src="/images/NNHiddenLayersExample.png" align="right" style="padding: 10px; width: 600px;"><p>The amount of hidden layers and nodes you utilize will drastically affect your Steps and Error for your output. Steps represents the amount of iterations your NN had to run through (the amount of times the <a href="http://en.wikipedia.org/wiki/Rprop">resilient backpropagation algorithm</a> stepped through and updated the weights). We mentioned previously that the weights on the arrows of the NN are updated with each training run; a training run is equivalent to one of these steps. The algorithm we use updates all the weights at the same time after one full step.<br/><br/> Sometimes your NN will not converge within the default 1000 steps and this results in a NN not being created (a reason multiple repetitions are good to have). The NN is considered to be converged iff the threshold reached by the NN is below .01 - the threshold is calculated through the use of partial derivatives with error. Simply, rate of change of error is below .01. If you wish to have a NN run with more steps, edit the default in the NN call with a custom script. Your error is simply the sum-squared error for your NN is in predicting the data it was trained upon. If the error is too low, then it could be a sign of overtraining, which is one of the motivations for the creation of the threshold stopping criterion.</p><a href="?lesson=nn3"><div class = "arrow" id ="backArrow"></div></a><a href="?lesson=nn5"><div class = "arrow" id ="forwardArrow"></div></a></div>'
	elif lesson == 'nn5':
		return '<div class="lesson" id="NPStext"><h2>Neural Networks</h2><h3>The Updating Of The Weights</h3><p>This section is so that you have a deeper understanding of what is going on behind the scenes of the NN algorithm.<br/><br/>The backpropagation algorithm that we use updates the weights between all of the nodes in a batch-style - that is, the weights are all updated at the same time (the end of each step). This is because you have finally reached the point of having a response value. Since you are training a NN, you have access to the true, or target, value that you were supposed to receive. So the algorithm knows the exact error between the target and the value received from the NN.<br/><img src="/images/neuralNet.png" align="center"><br/>To give you a better idea of how weights impact these nodes, we will provide you with a formula for a node, according to the diagram. Z<sub>11</sub> = 1*w<sub>7</sub> + X<sub>1</sub>*w<sub>1</sub> + X<sub>2</sub>*w<sub>3</sub> + X<sub>3</sub>*w<sub>5</sub>. This means that the Z<sub>11</sub> node will contain the result of the previous equation. Since there is another hidden layer, we then treat the Z<sub>1</sub> layer as inputs to the Z<sub>2</sub> layer. We repeat this update process for all nodes in this layer. Eventually, we have the equation that has the last hidden layer (and bias) input into the final, response node.<br/><br/>Weights in a NN are subject to a learning rate. A learning rate is used to adjust the weights for each arrow based upon how much magnitude the error contains. The higher the error, the more the algorithm \'learns.\' In most NN algorithms, you have one specified learning rate (namely, the Levenberg-Marquardt algorithm for NNs), but this resilient backpropagation version of the NN is a bit different. The weights are updated according to the sign of the partial derivative of the error. The sign of the partial derivative itself does not matter, but, rather, whether or not the sign was the same as the previous step (or iteration). If the next iteration produces the same sign, then the learning rate is 1.2 and if the next iteration produces a different sign, then the learning rate is .5. This algorithm performs very well because the series of weights and layers are nothing more than a series of linear combinations. So the updating of weights shifts the classification result, where classification is the numerical result. <br/></br>A full detailing of the RPROP+ NN algorithm that we implement is located in this <a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.21.1417">article</a></p><a href="?lesson=nn4"><div class = "arrow" id ="backArrow"></div></a><a href="?lesson=nn6"><div class = "arrow" id ="forwardArrow"></div></a></div>'
	elif lesson == 'nn6':
		return '<div class="lesson" id="NPStext"><h2>Neural Networks</h2><h3>Lesson</h3><p>Dataset Required: <a href="datasets/Basketball.csv">Basketball Data Set</a><br/>This lesson, like the PLS Regression lesson, utilizes the basketball dataset. Again, you will be predicting points per minute, given the predictor variables assists per minute, height, time played, and age. You only have two inputs you can alter. Increasing the amount of repetitions can only help you as we only look at your best NN. Your ultimate goal is to predict points per minute with a sum-squared error below .5. Just remember the tips we gave you in the previous sections about manipulating your hidden layers. Too many can create confounded results and too few can misrepresent more data than intended. Our built-in mechanisms avoid overfitting the model so you need not worry about that.</p><form target="_blank" action="http://portal.cs.cofc.edu/learn2mine/"> <!-- LINKS TO GALAXY --><input type="submit" value="Try Our Neural Network Lesson"> </form><a href="?lesson=nn5"><div class = "arrow" id ="backArrow"></div></a></div>'



	###############################################
	#		Case Studies Pages	      #
	###############################################
	elif lesson == 'case1':
		return '<div class="lesson" id="NPStext"><h2>Case Studies</h2><h3>Overview and Purpose</h3><p>Learn2Mine is great at teaching you data science algorithms and technologies, but we have not gone over coding concepts and practices. So using <i>Data Mining with R: Learning with Case Studies</i>, we have developed three lessons that will teach you R code while showing you more data science algorithms. The case studies we will be viewing come from chapters 2, 3, and 4 from <i>Data Mining with R</i>. <br/>In order to start these case studies, you have a few prerequisite steps to complete. First, you will have to make sure you have created your Learn2Mine key in Galaxy (your key/session can be quickly viewed in the \'<a href="?lesson=logins">My Logins</a>\' section). Creating this key gives you access to RStudio. After doing this, log in and follow the directions in \'<a href="?rstudio1">Using RStudio</a>\' to import our code and customize it. We give you three main files, denoted as caseStudyChapterX.R, along with an assortment of data files. You need not worry about installing libraries in R for these case studies because we have prepped every user to have the libraries required for these case studies. The lessons for this section will have to be submitted using the \'Custom Code\' tool in Galaxy. You do not need to worry about any of the inputs in the \'Custom Code\' tool except for the path to the R file. We have the other inputs there for flexibility purposes, but it is completely unnecessary for these case studies. To perform the tasks necessary for this lesson you will be required to read through the comments and code in the R files. The comments contain directions for tasks to do within the R code, as well as a guide to let you know what is going on with the code. Once we show you a task once in R, be expected to be tested on it soon afterward. In order to see feedback catered to what your errors were, then submit to Learn2Mine and look at the output in Galaxy.<br/><br/>Good luck and happy coding!</p><a href="?lesson=case2"><div class = "arrow" id ="forwardArrow"></div></a></div>'
	elif lesson == 'case2':
		return '<div class="lesson" id="NPStext"><h2>Case Studies</h2><h3>Case Study 1: Predicting Algae Blooms</h3>	<p>This first case study addresses the issue of algae blooms. These blooms result in destruction of the quality of the ecosystem in which they are occurring. Algae Blooms can easily result in eutrophication ~ the artificial increase of primary productivity of an aquatic ecosystem, which can lead to hypoxia (deprivation of oxygen in the water), further leading to the damaging of multiple species\' niches and the ecosystem overall. So if we can predict algae blooms early, then perhaps we can attempt to amend the issue and prevent future issues. The first step, however, is performing the data science techniques that will allow us to predict when and if these blooms will happen.<br/>Since this is the first case study you will be working with, it will not be difficult for you to complete. We have commented out a lot of the code - you will have to uncomment out a lot of this code so you can actually run it. In this case study, you will be working with the following algorithms and R techniques:<ul><li>Loading Data into R</li><li>Data Visualization and Summarization</li><li>Boxplots</li><li>Scaling and Filtering of Data</li><li>Multiple Linear Regression</li><li>Analysis of Variances (ANOVA)</li><li>Regression Trees</li><li>Evaluation Techniques</li></ul><br/>Proceed to RStudio and good luck! </p><a href="?lesson=case1"><div class = "arrow" id ="backArrow"></div></a><a href="?lesson=case3"><div class = "arrow" id ="forwardArrow"></div></a></div>'
	elif lesson == 'case3':
		return '<div class="lesson" id="NPStext"><h2>Case Studies</h2><h3>Case Study 2: Predicting Stock Market Returns</h3><p>Now we want to try a case study with a different flavor. We are going to try to apply data mining techniques to a common issue in business. In this day and age, investors are doing more than just watching stocks and investing with what their gut tells them. Data science has lent itself to allow for a new type of investing: algorithmic investing. How wonderful would it be if you could run an algorithm and know which stocks to buy, which to hold on to, and which to sell? Well, we are about to tackle these issues and, while we are doing it we are going to test you on your skills with R.<br/>This lesson does not have code commented out like the first case study did, but you will be required to do much more advanced coding. Anything that was shown to you in the first case study is understood as prerequisite knowledge at this point. <br/>In this case study, you will be working with the following algorithms and R techniques:<ul><li>Handling Time-Dependent Data in R</li><li>Visualizing with Candlecharts</li><li>Random Forests</li><li>Neural Networks</li><li>Support Vector Machines</li><li>Kernal and Smoothing Methods</li><li>Regression Splines</li></ul><br/>So hop on over to RStudio and start modifying the Chapter 3 case study file!<br/><br/>One known issue exists with this case study and we have commented out one of the predictive algorithms toward the end of the file in order to remedy this. Do not uncomment this out whenever you submit your code or else you will receive problematic results.</p><a href="?lesson=case2"><div class = "arrow" id ="backArrow"></div></a><a href="?lesson=case4"><div class = "arrow" id ="forwardArrow"></div></a></div>'
	elif lesson == 'case4':
		return '<div class="lesson" id="NPStext"><h2>Case Studies</h2><h3>Case Study 3: Detecting Fraudulent Transactions</h3><p>This case study revolves around the idea of fraud detection. Say you work for a business and you have a team of hundreds, or even thousands, of salespeople. You do not know each individual so you may have employees that are reporting fraudulent sales. Well, obviously you would like to detect this so you can remedy the situation. You are going to be working with marketing data that has a few known fraudulent transactions, several transactions that are proven to not be fraudulent, and a lot of data with unknown outcomes. Well, you want to predict these unknowns and see which are fraudulent and which are not. <br/>In this case study, you will be tested even more than in the previous case studies, but maybe you have learned enough that this will be the easiest case study yet. You will be working with the following algorithms and techniques:<ul><li>Creating and Viewing Data Features</li><li>Aggregation of Data and Apply Functions</li><li>Class Imbalance of Data</li><li>Outlier Handling</li><li>Modified Boxplot Rule</li><li>Naive Bayes</li><li>AdaBoost</li></ul><br/><br/>We removed a lot of the visualization code. You receive most of your visualization at the end which compares a lot of the predictive algorithms you run. Also, when running this tool in Galaxy for submission to Learn2Mine, be wary that it takes approximately 30 minutes to run the file. This is due to the dataset that you are using is around 400,000 lines long so the algorithms take a bit of time to run.</p><a href="?lesson=case3"><div class = "arrow" id ="backArrow"></div></a></div>'


	###############################################
	#		Sharing Code Pages	      #
	###############################################
	elif lesson == 'sharegit1':
		return '<div class="lesson" id="NPStext"><h2>Sharing Code</h2><h3>How to Share Code: What is Git?</h3><p>You may find yourself getting to the point in your skills where you want to collaborate and share code with others. Well, we have a way for you to do that within our RStudio server. Before we teach you, though, we have to introduce you to Git. Git is a source code management system that can store and track changes to files. The Git hosting service that we will be teaching you to use is <a href="https://bitbucket.org/">Bitbucket</a>. <br/>The first thing you will want to do is follow the instructions on <a href="https://confluence.atlassian.com/display/BITBUCKET/Set+up+Git+and+Mercurial">this page</a> (Mac and Linux users should see the infobox on the right of the page). This site gives you a full tutorial on what you can do with Git, but we will give you a condensed version on these next few pages.</p><a href="?lesson=sharegit2"><div class = "arrow" id ="forwardArrow"></div></a></div>'
	elif lesson == 'sharegit2':
		return '<div class="lesson" id="NPStext"><h2>Sharing Code</h2><h3>Repositories</h3><p>Alright, so now we will guide you through the account and repository creation process. Once you have created an account on <a href="https://bitbucket.org/account/signup/">Bitbucket</a>, you will be able to keep your own code repositories.<br/>There are multiple ways to create a repository. You can simply select the "Create your first repository" button to make a new directory that will serve as your repository. Alternatively, you can import a repository from an external source, but this is not what we are focusing on. So you have created your first repository. You fill out each of the fields (Leave \"Git\" as the Repository Type). One thing you should make a note of, however, is the Access Level of your repository. If a repository is private, then only people you invite to your repository can view it. If a repository is not private, then it is public and anyone with a link to your username or repository can view everything. You most likely want your repository to be private so select that option.<br/></p><h3>Code</h3><p>So now you have the options to make code from scratch or to push up an existing project. Each option here details how to create your repository. The existing project option merely allows you to start your repository with code you have already created. </p><a href="?lesson=sharegit1"><div class = "arrow" id ="backArrow"></div></a><a href="?lesson=sharegit3"><div class = "arrow" id ="forwardArrow"></div></a></div>'
	elif lesson == 'sharegit3':
		return '<div class="lesson" id="NPStext"><h2>Sharing Code</h2><h3>Committing, Pushing, and Pulling</h3><p>Once you have created your repository you are going to want to be able to modify and add changes to code. First, you may want to install a GUI for Git so you do not have to deal with the terminal (or command line) for this entire process (we recommend Git Gui). <img src="/images/gitgui.png" align="right" style="padding: 10px; width: 400px;">The Git Gui allows you to select from any of your repositories. Once you select a repository you will see any files that you have modified in your repository. When first starting, you should see a significantly higher number of files since every file will be new. In order to get your newly edited files to sync up with those on Bitbucket, you will need to go through a few steps. First, you will want to stage your changed files. This means that each file you changed is set up and ready to be put on the cloud. Next, you will want to type a \"commit message\" - this allows you to go back and read what the last edit to the file was and it gives your code a lot more readability when you come back to it. You finish that step by selecting commit. Now all of the files you staged should disappear from the staging area. You now have one last step to conduct in this process. You want to \"push\" these files up to Bitbucket. Whenever you push you will have the default selection to push to the \"origin\" or \"master\" branch - this is where you want your code to go. You will be prompted for your Bitbucket information whenever finishing the push. If everything has gone swimmingly, then you should be able to check Bitbucket and see your code.</p><a href="?lesson=sharegit2"><div class = "arrow" id ="backArrow"></div></a><a href="?lesson=sharegit4"><div class = "arrow" id ="forwardArrow"></div></a></div>'
	elif lesson == 'sharegit4':
		return '<div class="lesson" id="NPStext"><h2>Sharing Code</h2><h3>Fetching/Pulling and Merging</h3><p>So now let\'s enter a scenario where your collaborator has pushed up some code that you want to test. Well, your repository has that code, but your local machine does not, so let\'s fix that. This is referred to as pulling (or fetching). Within your Git Gui you will need to select the \"Remote\" option. From there you will select the \"Fetch From\" option. Then you select whatever branch you want to pull from (again, you will probably be pulling from \"origin\" or \"master\"). After this, select \"Merge\" and then \"Local Merge\" in order to sync up your code with the repository.<br/><br/>Now there is a common problem that can occur when conducting the merge. Suppose you and your collaborator edited the same file. So you have a commit that edited myFile.R and so did your collaborator. Well Git is not exactly the smartest so you will have to guide the process to clear up which file is which. You will know you need to go through this conflict/resolution if a merge comes up as red (failed). In the files with merge conflicts you will see items such as head and master origin. You want to sift through and delete the versions of code you do not want (along with the head and master labels) and keep the versions you do want. You will see the redundancy. There also exists tools and graphical editors for dealing with merging, but that is something you can search for yourself.<br/><br/>So now you know how to share your code with anyone you desire. So get out there and earn some badges! </p><a href="?lesson=sharegit3"><div class = "arrow" id ="backArrow"></div></a><a href="?lesson=sharegit5"><div class = "arrow" id ="forwardArrow"></div></a></div>'
	elif lesson == 'sharegit5':
		return '<div class="lesson" id="NPStext"><h2>Sharing Code</h2><h3>Cloning</h3><p><img src="/images/cloneLink.png" align="right" style="padding: 10px; width: 300px;">But wait... we only told you how to deal with repositories if you already have them in existence or if you want to create it from scratch. <br/><br/>Your collaborator may want you to get ahold of his/her repository that has already been populated. This idea is known as \"cloning\". On the right you will see a snippet from a github repository of ours. If you have been invited to a repository or if it is public, then you can go to the repository\'s page and view this snippet. What is very important about this, though, is the link next to the HTTPS button. If you want a copy of that repository on your machine, then you will copy the link that is next to this button. Once inside your Git Gui you will see the option to \"Clone Existing Repository\". You will paste this link in the \"Source Location\" textbox. The target directory is where, on your machine, you want the repository to be saved. After doing this, you are free to commit, pull, and push from the repository as needed.</p><a href="?lesson=sharegit4"><div class = "arrow" id ="backArrow"></div></a></div>'

	###############################################
	#		  Tutorial		      #	
	###############################################
	elif lesson == 'tutorial1':
 		jquery = '<script type="text/javascript" SRC="./Javascript/jquery.js"></script>'
		hint1text = 'Try breaking up each operation and putting them on individual lines - Your code should be 4 lines.'
		code1 = 'x = 1234<br>y = 169837<br>z = x^2 + 13*y/x<br>print(z)'
		problem1code = createTutorialProbs(hint1text,code1,1)

		code2='M = matrix(c(105,56,303,400,96,156),3,2)<br>M[(M>100 & M<200)]'
		hint2text = 'What are the 2 conditions you\'re looking for? Try indexing by those. What boolean operator joins them together?'
		problem2code = createTutorialProbs(hint2text,code2,2)
		return jquery+'<div class="Rlesson" id="NPStext"><h2>R Basic Tutorial</h2><p><ol><li>Complete the following problems</li></ol></p><p>Completion of this lesson requires that you upload a text file with the answers separated by numbers. Specifically, this must look like this:<br>1)<br>Your answer to #1<br>2)<br>Your answer to #2<br>etc<br></p><p>The following are 2 example problems similar to the ones you will find within Learn2Mine\'s lessons. Complete them using RStudio, and submit your final answer using Galaxy. Do not be afraid to use the hints or see part of the answer if you get stuck. Note that our answers are not the only way to do these tasks.</p><p><ol><li>R objects and simple arithmetic: Perform the following analysis using<br>x = 1234 and y = 169837<br>z = x^2 + 13*y/x<br>then type print(z)</li>'+problem1code+'<li>Given the following matrix, M = matrix(c(105,56,303,400,96,156),3,2) Slice out only those values less than 200 and greater than 100 (inclusive) using a logical statement. Print out the results and copy them to the file.</li>'+problem2code+'</div>'

	elif lesson == 'tutorial2':
 		jquery = '<script type="text/javascript" SRC="./Javascript/jquery.js"></script>'
		hint1text = ''
		code1 = 'df <- read.table(\'Analysis.txt\',col.names=c(\'season\',\'size\',\'speed\',\'mxPh\',\'mn02\',\'Cl\',\'no3\',\'nh4\',\'opo4\',\'po4\',\'chla\',\'a1\',\'a2\',\'a3\',\'a4\',\'a5\',\'a6\',\'a7\'))<br> head(df)'
		problem1code = createTutorialProbs(hint1text,code1,1)

		code2='df <- read.table(\'Analysis.txt\',col.names=c(\'season\',\'size\',\'speed\',\'mxPh\',\'mn02\',\'Cl\',\'no3\',\'nh4\',\'opo4\',\'po4\',\'chla\',\'a1\',\'a2\',\'a3\',\'a4\',\'a5\',\'a6\',\'a7\'))<br>df2 <- df[,11:18]<br>summary(df2)'
		hint2text = ''
		problem2code = createTutorialProbs(hint2text,code2,2)
		return jquery+'<div class="Rlesson" id="NPStext"><h2>R File I/O Tutorial</h2><p><ol><li>Complete the following problems</li></ol></p><p>Completion of this lesson requires that you upload a text file with the answers separated by numbers. Specifically, this must look like this:<br>1)<br>Your answer to #1<br>2)<br>Your answer to #2<br>etc<br></p><p>Now it\'s time to learn how to read and manipulate files in R. Perform the following tasks in RStudio with the dataset given.</p><p><ol><li>Read in the <a href="/datasets/Analysis.txt">Analysis.txt</a> file into a dataframe. Run the head command on your data, and then copy the results into your submission.</li>'+problem1code+'<li>Filter out the variables a1 - a7. Run the summary command on resulting dataframe. Copy those results into your submission.</li>'+problem2code+'</div>'

	elif lesson == 'tutorial3':
 		jquery = '<script type="text/javascript" SRC="./Javascript/jquery.js"></script>'
		hint1text = ''
		code1 = 'solution.my.sum <- function(my.array) {<br>&nbsp;&nbsp;&nbsp;  total = 0<br>&nbsp;&nbsp;&nbsp;  for (i in 1:length(my.array)) {<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;total = total + my.array[i]<br>&nbsp;&nbsp;&nbsp;  }<br>&nbsp;&nbsp;&nbsp;  return(total)<br>}'
		problem1code = createTutorialProbs(hint1text,code1,1)

		code2='solution.minimum3 <- function(v1,v2,v3) {<br>&nbsp;&nbsp;&nbsp;smallest = v1<br>&nbsp;&nbsp;&nbsp;if (v2 < smallest)<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;smallest = v2<br>&nbsp;&nbsp;&nbsp;if (v3 < smallest)<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;smallest = v3<br>&nbsp;&nbsp;&nbsp;return(smallest)<br>}'
		hint2text = ''
		problem2code = createTutorialProbs(hint2text,code2,2)
		return jquery+'<div class="Rlesson" id="NPStext"><h2>R Loops and Conditionals Tutorial</h2><p><ol><li>Complete the following problems</li></ol></p><p>Completion of this lesson requires that you upload a text file with the answers separated by numbers. Specifically, this must look like this:<br>1)<br>Your answer to #1<br>2)<br>Your answer to #2<br>etc<br></p><p>     [main lesson]            </p><p><ol><li> Write a function that loops through the values of an array and returns the sum of the values using a <b>for</b> loop. <b>You may not use the built in sum function.</b> Here is the function definition. You must fill in the middle. Instead of submitting the answer submit the working code.<br><br>my.sum &lt;- function(my.array) {<br>    &lt;insert code here><br>}<br></li>'+problem1code+'<li>Write a function that returns the minimum of three numbers. Here is the function definition. You may not use the <b>min</b> function. You must fill in the middle. Instead of submitting the answer submit the working code.<br><br>minimum3 &lt;- function(v1,v2,v3) {<br> &lt;insert code here><br>}<br></li>'+problem2code+'</div>'
	###############################################
	#		  R Lessons		      #	
	###############################################
	elif lesson == 'standardR':
		return '<div class="Rlesson" id="NPStext"><h2>Introduction to R, Rstudio, and Learn2Mine</h2><p><ol><li>Complete the Uploading Data Lesson on Learn2Mine</li><li>Complete the Standard R Lesson on Learn2Mine</li></ol></p><p>Completion of this lesson requires that you upload a text file with the answers separated by numbers. Specifically, this must look like this:<br>1)<br>Your answer to #1<br>2)<br>Your answer to #2<br>etc<br><br>The software will tell you which ones you have completed successfully, and which ones you still need to work on.</p><p><ol><li>R objects and simple arithmetic: Perform the following analysis using<br>x = 1234 and y = 169837<br>z = x^2 + 13*y/x<br>then type print(z)</li><li><b>Vectors:</b> Create a vector that has the following values: 1, 2, -3, 5. Then change the second value to -4. Then type print(z). Copy those results into your submission.</li><li><b>Vectorization:</b> Given two vectors (1,2,-3,5) and (3,4,13,-8). Add them and then multiple the result by 2. Then print it out to the screen. Copy those results into your submission.</li><li>) <b>Factors:</b> Create the following factor (name f) with 5 CS students, 3 Data Science students, and 1 CITA student using the official abbreviations (CSCI, DATA, and CITA). Display the factor using the table command and copy the results to the file.</li><li>Generate a sequence of numbers from 1 to 67 by 3 and then print this sequence to the screen with only 10 numbers printed per line. Resize your screen to make this happen.</li>	<li><b>Sub-setting:</b> Given the following matrix, M = matrix(c(105,56,303,400,96,156),3,2) Slice out only those values less than 200 and greater than 100 (inclusive) using a logical statement. Print out the results and copy them to the file.</li><li>Using the same matrix and using the which command, find the indices instead of the actual values. You can do this by taking the same equality from above (M <= 200 & M >= 100) and then adding the which command (i.e., which(M <= 200 & M >= 100). Copy those results into your submission.</li><li>Change the value in the second column and second row to -105. And then print out the columns of M. Copy those results into your submission.</li><li>Using the following list<br>myList = list(students=c(\'Paul\',\'Edward\',\'Mike\'),count=c(1,2))<br>Print out the contents of the students entry using the $ operator.</li><li>Print out the following dataframe.df = data.frame(students= c(\'Paul\',\'Edward\',\'Mike\'),grades=c(\'A\',\'B\',\'F\'))</li><li>Change the grade of Mike to a D and then print the results. This will initial give you trouble because grades is a factor. To change this you must execute the following:<br>levels(df$grades) = c(A,B,C,D,F). This tells R the possible values from grades, which up until that command were A, B, and F. Copy those results into your submission.</li><li>Change the column names of the data.frame to start with an uppercase letter using the colnames function. Print out the dataframe and copy those results into your submission.</li></ol></p><a href="http://portal.cs.cofc.edu/learn2mine-rstudio/">Practice in RStudio!</a></br><a href="http://portal.cs.cofc.edu/learn2mine/">Submit a Solution in Galaxy!</a></div></div>'
	elif lesson == 'fileIO':
		return '<div class="Rlesson" id="NPStext"><h2>File I/O and Basic File Processing</h2><p><ol><li>Complete the File I/O lesson on Learn2Mine</li></ol></p><p>Completion of this lesson requires that you upload a text file with the answers separated by numbers. Specifically, this must look like this:<br>1)<br>Your answer to #1<br>2)<br>Your answer to #2<br>etc<br><br>The software will tell you which ones you have completed successfully, and which ones you still need to work on.</p><p><ol><li>Read in the Analysis.txt file from the book into a dataframe using the headings that are specified in the book. Run the head command on your data, and then copy the results into your submission.</li><li>Filter out the variables a1 - a7. Run the summary command on resulting dataframe. Copy those results into your submission.</li><li>Using the filtered dataframe from question 2, create a new file on your system called number3.csv that stores the data in a text file that is delimited with a comma. This file must NOT contain quotes and it must NOT contain row numbers. To do this you can either use the write.table or write.csv function in R. To look up the documentation, type ?write.csv or ?write.table. Then open this new file and copy the contents into your submission.</li><li>Read the file that you created in step 3, but do so using the readLines command. This will read the file line by line. It is a great function to use if you do not have data structured in a fixed number of rows and columns. Run the head command on the resultof readLines. Copy those results into your submission.</li><li>Using the strsplit function, convert the second line returned by readLines into a numeric vector using the as.numeric function. Copy the results into your submission. Hint: The strsplit function returns a list that has embedded in it the matrix that you want to convert. To get at this matrix, you can use the [[1]] on the results. For example, if the result of strsplit is called results. Then you can convert this to numeric values by typing as.numeric(results[[1]]). The difference between double brackets and single brackets is described on the next page.</li></ol></p><p>R has three basic indexing operators, with syntax displayed by the following examples:<br> x[i]<br> x[i, j]<br> x[[i]]<br> x[[i, j]]<br> x$a<br> x$"a"<br>For vectors and matrices the [[ forms are rarely used, although they have some slight semantic differences from the [ form (e.g. it drops any names or dimnames attribute, and that partial matching is used for character indices). When indexing multi-dimensional structures with a single index,x[[i]] or x[i] will return the ith sequential element of x.<br>For lists, one generally uses [[ to select any single element, whereas [ returns a list of the selected elements.<br>The [[ form allows only a single element to be selected using integer or character indices, whereas[ allows indexing by vectors. Note though that for a list, the index can be a vector and each element of the vector is applied in turn to the list, the selected component, the selected component of that component, and so on. The result is still a single element.</p><a href="http://portal.cs.cofc.edu/learn2mine-rstudio/">Practice in RStudio!</a></br><a href="http://portal.cs.cofc.edu/learn2mine/">Submit a Solution in Galaxy!</a></div></div>'
	elif lesson == 'unknown':
		return '<div class="Rlesson" id="NPStext"><h2>Dealing with Unknown Values</h2><p><ol><li>Complete the Unknown Values Lesson on Learn2Mine</li></ol></p><p>Completion of this lesson requires that you upload a text file with the answers separated by numbers. Specifically, this must look like this:<br>1)<br>Your answer to #1<br>2)<br>Your answer to #2<br>etc<br><br>The software will tell you which ones you have completed successfully, and which ones you still need to work on.</p><p><ol><li>Read in the Analysis.txt file from the book into a dataframe using the headings that are specified in the book. <b>Remove any sample that has 1 or more unknown values.</b> Save the contents to a csv file using the command write.csv with the default options, and then copy the contents of this file into your submission.</li><li>How many rows were removed in problem 1?</li><li>Read in the Analysis.txt file from the book into a dataframe using the headings that are specified in the book. <b>Remove any sample that has 30% or more missing values.</b> Save the contents to a csv file using the command write.csv with the default options, and then copy the contents of this file into your submission.</li><li>How many rows were removed in problem 3?</li><li>Read in the Analysis.txt file from the book into a dataframe using the headings that are specified in the book. <b>Fill in the missing values of each column using the median if a continuous variable or the mode if a factor.</b> Save the contents to a csv file using the command write.csv with the default options, and then copy the contents of this file into your submission.</li><li>Read in the Analysis.txt file from the book into a dataframe using the headings that are specified in the book. <b>Fill in unknown values using the 5 nearest neighbors using the knnImputation function.</b> Save the contents to a csv file using the command write.csv with the default options, and then copy the contents of this file into your submission.</li></ol></p><a href="http://portal.cs.cofc.edu/learn2mine-rstudio/">Practice in RStudio!</a></br><a href="http://portal.cs.cofc.edu/learn2mine/">Submit a Solution in Galaxy!</a></div></div>'
	elif lesson == 'conditionals':
		return '<div class="Rlesson" id="NPStext"><h2>Conditionals with Functions</h2><p><ol><li>Complete the R Conditionals with Functions Lesson on Learn2Mine</li></ol></p><p>Completion of this lesson requires that you upload a text file with the answers separated by numbers. Specifically, this must look like this:<br>1)<br>Your answer to #1<br>2)<br>Your answer to #2<br>etc<br><br>The software will tell you which ones you have completed successfully, and which ones you still need to work on.</p><p><ol><li>Write a function that returns the minimum of three numbers. Here is the function definition. You may not use the <b>min</b> function. You must fill in the middle. Instead of submitting the answer submit the working code.<br>minimum3 &lt;- function(v1,v2,v3) {<br> &lt;insert code here><br>}<br></li><li>Write a function that returns the minimum of an array of numbers. Here is the function definition. You may not use the <b>min</b> function. You must fill in the middle. Instead of submitting the answer submit the working code.<br>minimum &lt;- function(my.array) {<br> &lt;insert code here><br>}<br><br></li></ol></p><a href="http://portal.cs.cofc.edu/learn2mine-rstudio/">Practice in RStudio!</a></br><a href="http://portal.cs.cofc.edu/learn2mine/">Submit a Solution in Galaxy!</a></div></div>'
	elif lesson == 'functions':
		return '<div class="Rlesson" id="NPStext"><h2>Functions</h2><p><ol><li>Complete the R Functions Lesson on Learn2Mine</li></ol></p><p>Completion of this lesson requires that you upload a text file with the answers separated by numbers. Specifically, this must look like this:<br>1)<br>Your answer to #1<br>2)<br>Your answer to #2<br>etc<br><br>The software will tell you which ones you have completed successfully, and which ones you still need to work on.</p><p><ol><li>Write a function that returns the average of three numbers. Here is the function definition. You must fill in the middle. Instead of submitting the answer submit the working code.<br><br>average3 &lt;- function(v1,v2,v3) {<br> &lt;insert code here><br>}<br></li><li>Write a function that find the roots of a quadratic equation and returns the results in an array. Here is the function definition. You must fill in the middle. Instead of submitting the answer submit the working code.<br><br>quadratic &lt;- function(a,b,c) {<br> &lt;insert code here><br>}<br></li><li>Write a function that returns the area of a triangle. Here is the function definition. You must fill in the middle. Instead of submitting the answer submit the working code.<br><br>area &lt;- function(height,width) {<br> &lt;insert code here><br>}<br></li></ol></p><a href="http://portal.cs.cofc.edu/learn2mine-rstudio/">Practice in RStudio!</a></br><a href="http://portal.cs.cofc.edu/learn2mine/">Submit a Solution in Galaxy!</a></div></div>'
	elif lesson == 'loops':
		return '<div class="Rlesson" id="NPStext"><h2>Loops with Functions</h2><<p><ol><li>Complete the R Loops with Functions Lesson on Learn2Mine</li></ol></p><p>Completion of this lesson requires that you upload a text file with the answers separated by numbers. Specifically, this must look like this:<br>1)<br>Your answer to #1<br>2)<br>Your answer to #2<br>etc<br><br>The software will tell you which ones you have completed successfully, and which ones you still need to work on.</p><p><ol><li>1) Write a function that loops through the values of an array and returns the sum of the values using a <b>for</b> loop. <b>You may not use the built in sum function.</b> Here is the function definition. You must fill in the middle. Instead of submitting the answer submit the working code.<br><br>my.sum &lt;- function(my.array) {<br>    &lt;insert code here><br>}<br></li><li>2) Write a function that loops through the values of an array and returns the geometric mean of the values using a <b>for</b> loop. <b>You may not use the built in sum function.</b> Here is the function definition. You must fill in the middle. Instead of submitting the answer submit the working code.<br><br>my.geometric.mean &lt;- function(my.array) {<br>    &lt;insert code here><br>}<br></li></ol></p><a href="http://portal.cs.cofc.edu/learn2mine-rstudio/">Practice in RStudio!</a></br><a href="http://portal.cs.cofc.edu/learn2mine/">Submit a Solution in Galaxy!</a></div></div>'
	elif lesson == 'predictionLesson1':
		return '<div class="Rlesson" id="NPStext"><h2>R Prediction Lesson 1</h2><p><ol><li> Complete the R Prediction 1 lesson on Learn2Mine</li></ol></p><p>Completion of this lesson requires that you upload a text file with the answers separated by numbers. Specifically, this must look like this:<br>1)<br>Your answer to #1<br>2)<br>Your answer to #2<br>etc<br><br>The software will tell you which ones you have completed successfully, and which ones you still need to work on.</p><p><ol><li>Start with the clean data demonstrated in Section 2.6.1. Create a linearmodel to predict a2 with all of the variables other variables (excluding a1 and a3 - a7). Then remove the NH4 and mxPH variables. What is the estimate of oPO4 after updating the linear model? Use the summary command to find it.</li><li>Continuing with your dataframe from number 1, create a regression tree to predict a2. What is the variable of the first node?</li><li>How many samples are in the left branch after the first split?</li><li>What is the minimum number of samples are in the leaf nodes?</li><li>How many internal nodes are pruned using the prune command and a cp of 0.08?</li></ol></p><a href="http://portal.cs.cofc.edu/learn2mine-rstudio/">Practice in RStudio!</a></br><a href="http://portal.cs.cofc.edu/learn2mine/">Submit a Solution in Galaxy!</a></div></div>'
	elif lesson == 'predictionLesson2':
		return '<div class="Rlesson" id="NPStext"><h2>R Prediction Lesson 2</h2><p><ol><li> Complete the R Prediction 2 lesson on Learn2Mine</li></ol></p><p>Completion of this lesson requires that you upload a text file with the answers separated by numbers. Specifically, this must look like this:<br>1)<br>Your answer to #1<br>2)<br>Your answer to #2<br>etc<br><br>The software will tell you which ones you have completed successfully, and which ones you still need to work on.</p><p><ol><li>Start with the clean data demonstrated at the beginning of Section 2.6.1. Create a linear model using all of the variables to predict a3, excluding the other algae. Specifically, save the output of the predict function to a file and then copy this as your answer to this problem. Use the write.csv function with the default parameters.</li><li>Start with the clean data demonstrated at the beginning of Section 2.6.1. Create a regression tree using rpart to predict a3. Specifically, save the output of the predict function to a file and then copy this as your answer to this problem. Use the write.csv function with the default parameters.<br><br>----For the remaining problems, make sure you use clean.algae----<br><br></li><li>Now the question is how do we really compare these two models? A start along the path to this comparison is the calculations of the mean absolute error, the mean squared error, and the normalized mean squared error. Use the regr.eval function to compute these quantities for both models. Copy the output as your answer to this question. Specifically, I want you to copy the quantities for the linear model and then the regression model. See the formatting guide for an example.</li><li>Using normalized mean squared error as the metric, which model performs better (linear regression or regression tree)? Note: make sure your answer is spelled exactly the same as the ones just specified, all lower case</li><li>Let\'s say that you want to compute something that doesn\'t come with the regr.eval function. One such example would be median squared error. Using the median function in R, compute the median squared error for the regression tree that you created above. Copy the output </li></ol></p><a href="http://portal.cs.cofc.edu/learn2mine-rstudio/">Practice in RStudio!</a></br><a href="http://portal.cs.cofc.edu/learn2mine/">Submit a Solution in Galaxy!</a></div>'
	elif lesson == 'stockMarket':
		return '<div class="Rlesson" id="NPStext"><h2>Predicting Stock Market 1</h2><p><ol><li>Complete the Predicting Stock Market 1 Lesson on Learn2Mine</li></ol></p><p>Completion of this lesson requires that you upload a text file with the answers separated by numbers. Specifically, this must look like this:<br>1)<br>Your answer to #1<br>2)<br>Your answer to #2<br>etc<br><br>The software will tell you which ones you have completed successfully, and which ones you still need to work on.</p><p>Create a script that starts as follows:<br>library(quantmod)<br><br># Add set digits and set width<br>options(digits = 3,width=100)<br><br># Download the IBM stock performance using the following code<br>setSymbolLookup(IBM=list(name=\'IBM\',src=\'yahoo\'),<br> &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;USDEUR=list(name=\'USD/EUR\',src=\'oanda\',<br> &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;from=as.Date(\'2013-01-01\')))<br>getSymbols(c(\'IBM\',\'USDEUR\'))<br></p><p><ol><li>The above code downloads the IBM stock data from Yahoo. Subset the data, such that only days between Jan 1, 2010 and Jan 1, 2013 are included. Then submit the output of the head command on this data.</li><li>Change the headers of the IBM dataset to match those of the book (e.g., Open, High, Low). Then submit the output of the head command on this data.</li><li>Create a random forest model using the code specified in the book. Make sure you specify set.seed(1234) before you build the model. Specifically, create the model with training.per = c(start(IBM),index(IBM["2012-01-04"])) and the number of trees equal to 50. Then use the importance function with type 1 to pring all of the variable names that have importance greater than 5.</li></ol></p><a href="http://portal.cs.cofc.edu/learn2mine-rstudio/">Practice in RStudio!</a></br><a href="http://portal.cs.cofc.edu/learn2mine/">Submit a Solution in Galaxy!</a></div></div>'


	###############################################
	#		Logins Page		      #	
	###############################################
	elif lesson == 'logins':
		return '<div class="lesson" id="NPStext"><h2>Logins</h2><p> Use these logins to get into your RStudio account. Your RStudio account will be activated as soon as you use the "Key Tool" in Galaxy, entering the value listed as "password" below:<br/><br/>Username: '+str(rstudioUser)+'<br />Password: '+str(session)+'</p>Thnk your key has been compromised?  <a href="/newKey">Generate a new one</a> <br>(<b>NOTE:</b>) You will need to recreate your key with the "Create Learn2Mine Key" tool in Galaxy after doing this.</div></div>'

